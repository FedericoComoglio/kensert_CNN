---
title: "Deep transfer learning - using pre-trained CNNs to classify images from the Broad Bioimage Benchmark Collection"
author: "Federico Comoglio"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    theme: journal #cerulean
    highlight: monochrome
    toc: true
    toc_float: true
    code_folding: show
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, cache = FALSE, fig.align = 'center', fig.width = 6, fig.height = 6)
```


## Introduction

Image-based phenotypic profiling is an emerging technology that aims at summarizing cellular phenotypes so that similarities between profiles reflect similarities between samples. Images from the Broad Bioimage Benchmark Collection (BBBC) are a valuable benchmark for testing and validating image-based profiling methods with respect to their ability to predict the mechanisms of action of a compendium of drugs. Here, we reproduce the analyses in X et al. using the image set at [https://data.broadinstitute.org/bbbc/BBBC021/](https://data.broadinstitute.org/bbbc/BBBC021/).

### Image set

The image set contains 39,600 images (1024x1280, 13,200 fields of view imaged in three channels) of MCF-7 breast cancer cells treated for 24 h with a collection of 113 small molecules at eight concentrations. The cells were fixed, labeled for DNA, F-actin, and Î’-tubulin, and imaged by fluorescent microscopy. Images are in TIFF format, provided in 55 ZIP archives, one for each microtiter plate.

```{r load libs}
library(reticulate)
library(here)

use_python('/opt/miniconda/bin/python3.6')

# test config:
#  conda_version(conda = '/opt/miniconda/bin/conda')
```


### Generate images

1. Download all `55 zip files` from [https://data.broadinstitute.org/bbbc/BBBC021/](https://data.broadinstitute.org/bbbc/BBBC021/). Here, I just dowloaded one archive (i.e. one microtiter plate) to first test the pre-processing.

```{bash, eval = FALSE}
wget https://data.broadinstitute.org/bbbc/BBBC021/BBBC021_v1_images_Week1_22123.zip .
wget https://data.broadinstitute.org/bbbc/BBBC021/BBBC021_v1_image.csv .
wget https://data.broadinstitute.org/bbbc/BBBC021/BBBC021_v1_moa.csv .
```

2. Unzip and move all 55 folders to the project directory: `here()`.
3. Download `BBBC021_v1_image.csv` and `BBBC021_v1_moa.csv` from same website and place in the same folder.
4. Run `generate_dataset_bbbc021.py` and enter the folder name containing all the image-folders.
5. Generated images will be saved to folder `images_bbbc021/`, and y labels will be outputted to a `.csv` file.

Data augmentation is applied to increase the number of images for training. To this end, each original image is cropped 4 times.

```{python}
import numpy as np
import pandas as pd
import os
from PIL import Image
import matplotlib.pyplot as plt

dirname = '/analyses/transfer-learning-cnn/Week1_22123/'

if not (any("BBBC021_v1_image.csv" in s for s in os.listdir(dirname)) and
any("BBBC021_v1_moa.csv" in s for s in os.listdir(dirname))):
    raise ValueError("BBBC021_v1_image.csv and BBBC021_v1_moa.csv need to be in directory")
```

```{python}
# Load an image
data = plt.imread(dirname + 'Week1_150607_G10_s3_w18B9248AB-3305-40CA-8AA1-757C67A527AA.tif')
data.shape

# Display the image
plt.imshow(data)
plt.show()
```

```{python}
# the number of cropped images from the original image
crops = 4

def slide_window(img, dims = (512, 640)):
    window_height, window_width = dims
    y, x = img.shape[:2]
    crop_images = np.zeros((4, 512, 640, 3)) # dtype="uint8"
    
    index = 0
    col = 0
    for i in range(y//window_height):
        row = 0
        for j in range(x//window_width):
            crop_images[index] = img[row : row + window_height, col : col + window_width, :]
            row += window_height
            index += 1
        col += window_width
    return crop_images

def anscombe(x):
    x = x.astype(np.float32)
    return (2.0*np.sqrt(x + 3.0/8.0))

def DMSO_normalization(x, y, idx, crops, rm_imgs):
    '''
    Mean DMSO per plate per channel is subtracted from each [non-DMSO] image pixel-wise.
      input x is the transformed non-DMSO image
      input y is the transformed DMSO image
    the output is the non-DMSO image that has been normalized by DMSO statistics
    '''
    channels = x.shape[3]
    x = x.astype(np.float32)

    # Subtracting mean DMSO and divide std DMSO from/by non-DMSO images pixel-wise
    for i in range(channels):
        x[:,:,:,i] -= y[:,:,:,i].mean()
        x[:,:,:,i] /= y[:,:,:,i].std()

    # Map values to 8-bit integers and save to file
    # if crops = 4, slide_window function is used to generate cropped images.
    for i,j in zip(range(x.shape[0]), idx):

        # NewValue = (((OldValue - OldMin) * (NewMax - NewMin)) / (OldMax - OldMin)) + NewMin

        # Map to 8-bit int
        OldRange = (x[i,:,:,:].max() - x[i,:,:,:].min())
        NewRange = (255 - 0)
        xt = (((x[i,:,:,:] - x[i,:,:,:].min()) * NewRange) / OldRange) + 0
        imgs = slide_window(xt)
        for i,img in enumerate(imgs):
            if ((img > (NewRange/5.1)).sum()/img.size) <= 0.002:
                rm_imgs.append(i+j)

                continue
            img_cropped = Image.fromarray(img.astype("uint8"))
            # Save images to directory
            img_cropped.save("images_bbbc021/bbbc021_%s.png" % str(j+i-len(rm_imgs)))

    return

# read mechanism file
moa  = pd.read_csv(dirname + '/BBBC021_v1_moa.csv')
# read data file which link images to compound/concentration.
# which can then be linked to moa file
data = pd.read_csv(dirname + '/BBBC021_v1_image.csv')

labels = []
# keep track of images
count = 0
# keep track of dataset
dataset = 1
# List specifying images to be removed
rm_imgs = []
# Iterate through different directories (different plates)
for f in (f for f in os.listdir(dirname) if 'Week' in f):
    # Assign new variable for current plate
    plate_data = data[data['Image_PathName_DAPI'].str.contains(f)]

    idx = []
    plate_X = []
    plate_Y = []
    # Iterate through current plate
    for index, row in plate_data.iterrows():
        # Exclude all taxol compounds except certain examples from Week 1 plates
        if row['Image_Metadata_Compound'] == "taxol":
            if not (
                    'Week1_' in row['Image_PathName_DAPI']  and
                    'D0' in row['Image_Metadata_Well_DAPI'] and
                        (
                        "0.3" in str(row['Image_Metadata_Concentration']) or
                        "1.0" in str(row['Image_Metadata_Concentration']) or
                        "3.0" in str(row['Image_Metadata_Concentration'])
                        )
                    ):
                continue

        # Extract compounds that have a MOA annotation
        if moa[(moa['compound']      == row['Image_Metadata_Compound']) &
               (moa['concentration'] == row['Image_Metadata_Concentration'])].shape[0] > 0:

            #Read the images
            img_DAPI    = Image.open(dirname+'/%s/%s' % (f, row['Image_FileName_DAPI']))
            img_DAPI    = np.array(img_DAPI)

            img_Tubulin = Image.open(dirname+'/%s/%s' % (f, row['Image_FileName_Tubulin']))
            img_Tubulin = np.array(img_Tubulin)

            img_Actin   = Image.open(dirname+'/%s/%s' % (f, row['Image_FileName_Actin']))
            img_Actin   = np.array(img_Actin)

            # Make it RGB (stack the three channels) and append to list of images of current plate
            img_stack   = np.dstack((img_Actin, img_Tubulin, img_DAPI))
            plate_X.append(img_stack)

            # Obtain mechanism, compound and concentration for image
            mechanism  = moa[(moa['compound']      == row['Image_Metadata_Compound']) &
                             (moa['concentration'] == row['Image_Metadata_Concentration'])]

            # Append additional labels (apart from mechanism, compounds, concentrations) to labels list.
            # And all different rotations/mirrors (x 8).
            if row['Image_Metadata_Compound'] != 'DMSO':
                [labels.append([mechanism.values.tolist()[0][0],
                                mechanism.values.tolist()[0][1],
                                mechanism.values.tolist()[0][2],
                                row['Image_Metadata_Plate_DAPI'],
                                row['Image_Metadata_Well_DAPI'],
                                row['Replicate']]) for i in range(crops)]

                idx.append(count)
                count += crops

            plate_Y.append([mechanism.values.tolist()[0][0],
                            mechanism.values.tolist()[0][1],
                            mechanism.values.tolist()[0][2],
                            row['Image_Metadata_Plate_DAPI'],
                            row['Image_Metadata_Well_DAPI'],
                            row['Replicate']])

    plate_Y      = np.asarray(plate_Y)
    dmso_idx     = np.where(plate_Y[:,0] == "DMSO")[0]
    non_dmso_idx = np.where(plate_Y[:,0] != "DMSO")[0]

    if len(non_dmso_idx) > 0:
        plate_X = np.asarray(plate_X)
        plate_X = anscombe(plate_X)
        #plate_X = inverse_anscombe(plate_X)
        DMSO_normalization(plate_X[non_dmso_idx], plate_X[dmso_idx], idx, crops, rm_imgs)
    print('Number of compounds transformed = ' + str(count) + '; dataset = ' + str(dataset))
    dataset += 1

for index in sorted(rm_imgs, reverse=True):
    del labels[index]

df = pd.DataFrame(labels)
df.to_csv('bbbc021_labels.csv',
          header=["compound", "concentration", "moa", "plate", "well", "replicate"], sep=';')
```


